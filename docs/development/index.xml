<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>开发与部署指南 on FastGPT</title><link>https://doc.tryfastgpt.ai/docs/development/</link><description>Recent content in 开发与部署指南 on FastGPT</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><atom:link href="https://doc.tryfastgpt.ai/docs/development/index.xml" rel="self" type="application/rss+xml"/><item><title>快速开始本地开发</title><link>https://doc.tryfastgpt.ai/docs/development/intro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/intro/</guid><description>本文档介绍了如何设置开发环境以构建和测试 FastGPT，。
前置依赖项 link您需要在计算机上安装和配置以下依赖项才能构建 FastGPT：
Git Docker（构建镜像） Node.js v18.17 / v20.x（版本尽量一样，可以使用nvm管理node版本） pnpm 版本 8.6.0 (目前官方的开发环境) make命令: 根据不同平台，百度安装 (官方是GNU Make 4.3) 开始本地开发 link check_circle 用户默认的时区为 Asia/Shanghai,非 linux 环境时候，获取系统时间会异常，本地开发时候，可以将用户的时区调整成 UTC（+0）。 建议先服务器装好数据库，再进行本地开发。 1. Fork 存储库 link您需要 Fork 存储库。
2. 克隆存储库 link克隆您在 GitHub 上 Fork 的存储库：
git clone git@github.com:&amp;lt;github_username&amp;gt;/FastGPT.git 目录简要说明
projects 目录下为 FastGPT 应用代码。其中 app 为 FastGPT 核心应用。（后续可能会引入其他应用） NextJS 框架前后端放在一起，API 服务位于 src/pages/api 目录内。 packages 目录为共用代码，通过 workspace 被注入到 projects 中，已配置 monorepo 自动注入，无需额外打包。 3. 安装数据库 link第一次开发，需要先部署数据库，建议本地开发可以随便找一台 2C2G 的轻量小数据库实践，或者新建文件夹并配置相关文件用以运行docker。数据库部署教程：Docker 快速部署。部署完了，可以本地访问其数据库。</description></item><item><title>Sealos 一键部署</title><link>https://doc.tryfastgpt.ai/docs/development/sealos/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/sealos/</guid><description>部署架构图 link 多模型支持 linkFastGPT 使用了 one-api 项目来管理模型池，其可以兼容 OpenAI 、Azure 、国内主流模型和本地模型等。
可参考：Sealos 快速部署 OneAPI
一键部署 link使用 Sealos 服务，无需采购服务器、无需域名，支持高并发 &amp;amp; 动态伸缩，并且数据库应用采用 kubeblocks 的数据库，在 IO 性能方面，远超于简单的 Docker 容器部署。可以根据需求，再下面两个区域选择部署。
新加坡区 link新加披区的服务器在国外，可以直接访问 OpenAI，但国内用户需要梯子才可以正常访问新加坡区。国际区价格稍贵，点击下面按键即可部署👇
北京区 link北京区服务提供商为火山云，国内用户可以稳定访问，但无法访问 OpenAI 等境外服务，价格约为新加坡区的 1/4。点击下面按键即可部署👇
开始部署 link由于需要部署数据库，部署完后需要等待 2~4 分钟才能正常访问。默认用了最低配置，首次访问时会有些慢。
根据提示，输入root_password，和 openai/oneapi 的地址和密钥。
点击部署后，会跳转到应用管理页面。可以点击fastgpt主应用右侧的详情按键（名字为 fastgpt-xxxx）， 如下图所示。
点击详情后，会跳转到 fastgpt 的部署管理页面，点击外网访问地址中的链接，即可打开 fastgpt 服务。
如需绑定自定义域名、修改部署参数，可以点击右上角变更，根据 sealos 的指引完成。
登录 link用户名：root
密码是刚刚一键部署时设置的root_password
修改配置文件和环境变量 link在 Sealos 中，你可以打开应用管理（App Launchpad）看到部署的 FastGPT，可以打开数据库（Database）看到对应的数据库。
在应用管理中，选中 FastGPT，点击变更，可以看到对应的环境变量和配置文件。
🤖
在 Sealos 上，FastGPT 一共运行了 1 个服务和 2 个数据库，如暂停和删除请注意数据库一同操作。（你可以白天启动，晚上暂停它们，省钱大法）</description></item><item><title>Docker Compose 快速部署</title><link>https://doc.tryfastgpt.ai/docs/development/docker/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/docker/</guid><description>部署架构图 link 🤖
MongoDB：用于存储除了向量外的各类数据
PostgreSQL/Milvus：存储向量数据
OneAPI: 聚合各类 AI API，支持多模型调用 （任何模型问题，先自行通过 OneAPI 测试校验）
推荐配置 linkPgVector版本 link体验测试首选
环境 最低配置（单节点） 推荐配置 测试 2c2g 2c4g 100w 组向量 4c8g 50GB 4c16g 50GB 500w 组向量 8c32g 200GB 16c64g 200GB Milvus版本 link暂不推荐，部分系统存在精度丢失，等待修复。
对于千万级以上向量性能更优秀。
点击查看 Milvus 官方推荐配置
环境 最低配置（单节点） 推荐配置 测试 2c8g 4c16g 100w 组向量 未测试 500w 组向量 zilliz cloud版本 link暂不推荐，部分系统存在精度丢失，等待修复。
亿级以上向量首选。
由于向量库使用了 Cloud，无需占用本地资源，无需太关注。
前置工作 link1. 确保网络环境 link如果使用OpenAI等国外模型接口，请确保可以正常访问，否则会报错：Connection error 等。 方案可以参考：代理方案
2. 准备 Docker 环境 link Linux MacOS Windows # 安装 Docker curl -fsSL https://get.</description></item><item><title>配置文件介绍</title><link>https://doc.tryfastgpt.ai/docs/development/configuration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/configuration/</guid><description>由于环境变量不利于配置复杂的内容，新版 FastGPT 采用了 ConfigMap 的形式挂载配置文件，你可以在 projects/app/data/config.json 看到默认的配置文件。可以参考 docker-compose 快速部署 来挂载配置文件。
开发环境下，你需要将示例配置文件 config.json 复制成 config.local.json 文件才会生效。
这个配置文件中包含了系统参数和各个模型配置：
4.6.8+ 版本新配置文件示例 link { &amp;#34;feConfigs&amp;#34;: { &amp;#34;lafEnv&amp;#34;: &amp;#34;https://laf.dev&amp;#34; // laf环境。 https://laf.run （杭州阿里云） ,或者私有化的laf环境。如果使用 Laf openapi 功能，需要最新版的 laf 。 }, &amp;#34;systemEnv&amp;#34;: { &amp;#34;vectorMaxProcess&amp;#34;: 15, &amp;#34;qaMaxProcess&amp;#34;: 15, &amp;#34;pgHNSWEfSearch&amp;#34;: 100 // 向量搜索参数。越大，搜索越精确，但是速度越慢。设置为100，有99%&amp;#43;精度。 }, &amp;#34;llmModels&amp;#34;: [ { &amp;#34;model&amp;#34;: &amp;#34;gpt-4o-mini&amp;#34;, // 模型名(对应OneAPI中渠道的模型名) &amp;#34;name&amp;#34;: &amp;#34;gpt-4o-mini&amp;#34;, // 模型别名 &amp;#34;avatar&amp;#34;: &amp;#34;/imgs/model/openai.svg&amp;#34;, // 模型的logo &amp;#34;maxContext&amp;#34;: 125000, // 最大上下文 &amp;#34;maxResponse&amp;#34;: 16000, // 最大回复 &amp;#34;quoteMaxToken&amp;#34;: 120000, // 最大引用内容 &amp;#34;maxTemperature&amp;#34;: 1.</description></item><item><title>使用 One API 接入 Azure、ChatGLM 和本地模型</title><link>https://doc.tryfastgpt.ai/docs/development/one-api/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/one-api/</guid><description>默认情况下，FastGPT 只配置了 GPT 的模型，如果你需要接入其他模型，需要进行一些额外配置。 One API 是一个 OpenAI 接口管理 &amp;amp; 分发系统，可以通过标准的 OpenAI API 格式访问所有的大模型，开箱即用。 FastGPT 可以通过接入 One API 来实现对不同大模型的支持。One API 的部署方法也很简单。 FastGPT 与 One API 关系 link可以把 One API 当做一个网关。
部署 linkDocker 版本 link已加入最新的 docker-compose.yml 文件中。
Sealos - MySQL 版本 linkMySQL 版本支持多实例，高并发。
直接点击以下按钮即可一键部署 👇
部署完后会跳转「应用管理」，数据库在另一个应用「数据库」中。需要等待 1~3 分钟数据库运行后才能访问成功。
Sealos - SqlLite 版本 linkSqlLite 版本不支持多实例，适合个人小流量使用，但是价格非常便宜。
1. 点击打开 Sealos 公有云
2. 打开 AppLaunchpad(应用管理) 工具
3. 点击创建新应用
4. 填写对应参数
镜像：ghcr.io/songquanpeng/one-api:latest
打开外网访问开关后，Sealos 会自动分配一个可访问的地址，不需要自己配置。
填写完参数后，点击右上角部署即可。环境变量：</description></item><item><title>私有部署常见问题</title><link>https://doc.tryfastgpt.ai/docs/development/faq/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/faq/</guid><description>一、错误排查方式 link遇到问题先按下面方式排查。
docker ps -a 查看所有容器运行状态，检查是否全部 running，如有异常，尝试docker logs 容器名查看对应日志。 容器都运行正常的，docker logs 容器名 查看报错日志 带有requestId的，都是 OneAPI 提示错误，大部分都是因为模型接口报错。 无法解决时，可以找找Issue，或新提 Issue，私有部署错误，务必提供详细的日志，否则很难排查。 二、通用问题 link能否纯本地运行 link可以。需要准备好向量模型和LLM模型。
其他模型没法进行问题分类/内容提取 link 看日志。如果提示 JSON invalid，not support tool 之类的，说明该模型不支持工具调用或函数调用，需要设置toolChoice=false和functionCall=false，就会默认走提示词模式。目前内置提示词仅针对了商业模型API进行测试。问题分类基本可用，内容提取不太行。 如果已经配置正常，并且没有错误日志，则说明可能提示词不太适合该模型，可以通过修改customCQPrompt来自定义提示词。 页面崩溃 link 关闭翻译 检查配置文件是否正常加载，如果没有正常加载会导致缺失系统信息，在某些操作下会导致空指针。 95%情况是配置文件不对。会提示 xxx undefined 提示URI malformed，请 Issue 反馈具体操作和页面，这是由于特殊字符串编码解析报错。 某些api不兼容问题（较少） 开启内容补全后，响应速度变慢 link 问题补全需要经过一轮AI生成。 会进行3~5轮的查询，如果数据库性能不足，会有明显影响。 对话接口报错或返回为空(core.chat.Chat API is error or undefined) link 检查 AI 的 key 问题：通过 curl 请求看是否正常。务必用 stream=true 模式。并且 maxToken 等相关参数尽量一致。 如果是国内模型，可能是命中风控了。 查看模型请求日志，检查出入参数是否异常。 # curl 例子。 curl --location --request POST &amp;#39;https://xxx.</description></item></channel></rss>